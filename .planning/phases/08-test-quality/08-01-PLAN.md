---
phase: 08-test-quality
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/mcp_json_yaml_toml/tests/verify_features.py
  - packages/mcp_json_yaml_toml/tests/test_schemas.py
  - packages/mcp_json_yaml_toml/tests/test_diff.py
  - packages/mcp_json_yaml_toml/tests/test_lmql_constraints.py
  - packages/mcp_json_yaml_toml/tests/test_yq_wrapper.py
autonomous: true

must_haves:
  truths:
    - "verify_features.py test_hints() uses assert statements instead of print-only verification"
    - "test_schemas.py tests _parse_extension_schemas behavior through IDESchemaProvider or SchemaManager public API"
    - "Repetitive test data in test_diff.py, test_lmql_constraints.py, and test_yq_wrapper.py uses @pytest.mark.parametrize"
  artifacts:
    - path: "packages/mcp_json_yaml_toml/tests/verify_features.py"
      provides: "Proper assert-based test_hints()"
      contains: "assert"
    - path: "packages/mcp_json_yaml_toml/tests/test_schemas.py"
      provides: "Public API tests replacing _parse_extension_schemas direct calls"
    - path: "packages/mcp_json_yaml_toml/tests/test_diff.py"
      provides: "Parametrized tool-level diff tests"
      contains: "@pytest.mark.parametrize"
    - path: "packages/mcp_json_yaml_toml/tests/test_lmql_constraints.py"
      provides: "Parametrized constraint validation tests"
      contains: "@pytest.mark.parametrize"
    - path: "packages/mcp_json_yaml_toml/tests/test_yq_wrapper.py"
      provides: "Parametrized version parsing tests"
      contains: "@pytest.mark.parametrize"
  key_links:
    - from: "packages/mcp_json_yaml_toml/tests/test_schemas.py"
      to: "packages/mcp_json_yaml_toml/schemas/manager.py"
      via: "SchemaManager or IDESchemaProvider public methods"
      pattern: "SchemaManager|IDESchemaProvider"
---

<objective>
Fix test assertions, refactor private method tests to public API, and convert repetitive test data to parametrized tests.

Purpose: Address TEST-01 (private method testing), TEST-04 (repetitive test data), and TEST-05 (verify_features.py assertions) requirements. These are structural test quality improvements that change HOW tests validate behavior without changing WHAT they test.

Output: Five modified test files with proper assertions, public API testing, and parametrized data.
</objective>

<execution_context>
@/home/ubuntulinuxqa2/.claude/get-shit-done/workflows/execute-plan.md
@/home/ubuntulinuxqa2/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@packages/mcp_json_yaml_toml/tests/verify_features.py
@packages/mcp_json_yaml_toml/tests/test_schemas.py
@packages/mcp_json_yaml_toml/tests/test_diff.py
@packages/mcp_json_yaml_toml/tests/test_lmql_constraints.py
@packages/mcp_json_yaml_toml/tests/test_yq_wrapper.py
@packages/mcp_json_yaml_toml/schemas/__init__.py
@packages/mcp_json_yaml_toml/schemas/ide_cache.py
@packages/mcp_json_yaml_toml/schemas/manager.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix verify_features.py assertions and refactor test_schemas.py private method tests</name>
  <files>
    packages/mcp_json_yaml_toml/tests/verify_features.py
    packages/mcp_json_yaml_toml/tests/test_schemas.py
  </files>
  <action>
**verify_features.py (TEST-05):**

Replace the print-only `test_hints()` function with proper pytest assertions. The function currently uses `call_tool(data_query, ...)` to query a YAML file and prints whether pagination is active -- add assert statements that verify the return structure.

Specific changes:

1. Remove or reduce print() statements (keep minimal diagnostic output if desired)
2. Add assertions: `assert isinstance(result, dict)`, `assert "result" in result or "paginated" in result`
3. If `result.get("paginated")` is True, assert that `"advisory"` key exists and `"next_cursor"` key exists
4. If not paginated, assert `"result"` key exists and its string length is > 0
5. The function must work both when run standalone (`__main__`) and via pytest. Keep the `if __name__ == "__main__"` block.

**test_schemas.py (TEST-01):**

There are 4 tests in `TestParseExtensionSchemas` class (lines ~340-430) that import and call `_parse_extension_schemas` directly. This is the private function from `schemas/ide_cache.py`.

Refactor these to test through the public `IDESchemaProvider` class instead:

1. Import `IDESchemaProvider` from `mcp_json_yaml_toml.schemas`
2. Instead of calling `_parse_extension_schemas(extension_dir)` directly, create an `IDESchemaProvider` instance and use its public methods/attributes to verify the same behavior
3. Alternatively, use `_build_ide_schema_index([extension_dir])` which is in `__all__` and is a higher-level public API
4. The key behavior being tested: parsing extension directories to find schema mappings. The test creates mock directory structures with `package.json` files containing schema contributions -- this behavior can be verified through `_build_ide_schema_index()` which calls `_parse_extension_schemas` internally
5. Keep the same test coverage (valid schemas, missing files, malformed JSON, empty contributions)

IMPORTANT: `_parse_extension_schemas` IS in `__all__` (exported), so the tests aren't wrong per se. But the requirement TEST-01 asks us to test through higher-level API. Use `_build_ide_schema_index()` as the entry point since it exercises `_parse_extension_schemas` and `_find_potential_extension_dirs` together, testing the real integration path.
</action>
<verify>

```bash
uv run pytest packages/mcp_json_yaml_toml/tests/verify_features.py packages/mcp_json_yaml_toml/tests/test_schemas.py -v --no-header 2>&1 | tail -30
```

All tests pass. verify_features.py::test_hints contains assert statements. test_schemas.py no longer has direct `_parse_extension_schemas` calls (uses `_build_ide_schema_index` or `IDESchemaProvider` instead).
</verify>
<done>
verify_features.py test_hints() has proper assertions (not just prints). test_schemas.py TestParseExtensionSchemas tests go through public API (\_build_ide_schema_index or IDESchemaProvider). All existing test behaviors preserved.
</done>
</task>

<task type="auto">
  <name>Task 2: Convert repetitive test data to @pytest.mark.parametrize</name>
  <files>
    packages/mcp_json_yaml_toml/tests/test_diff.py
    packages/mcp_json_yaml_toml/tests/test_lmql_constraints.py
    packages/mcp_json_yaml_toml/tests/test_yq_wrapper.py
  </files>
  <action>
**test_diff.py (TEST-04):**

The `TestDataDiffTool` class has tests that repeat identical file creation patterns:

- `test_identical_json_files` and `test_different_json_files` both create two JSON files with similar setup
- `test_cross_format_json_vs_yaml` and `test_cross_format_json_vs_yaml_different` follow same pattern
- `test_missing_first_file` and `test_missing_second_file` are symmetric error cases

Consolidate:

1. Parametrize the missing file tests: `@pytest.mark.parametrize("missing", ["first", "second"])` with a single test body that creates one file and skips the other based on parameter
2. Keep the identical/different and cross-format tests separate since they assert different outcomes -- these are NOT good parametrize candidates (different assertions). Only parametrize tests with identical logic but different data.

**test_lmql_constraints.py (TEST-04):**

Several constraint test classes have repetitive valid/invalid patterns that can be parametrized:

1. `TestYQPathConstraint`: parametrize valid paths (`".name"`, `".db.host"`, `".servers[0]"`, `".servers[]"`, `".db.host | keys"`) into a single `test_valid_paths` with `@pytest.mark.parametrize("path", [...])`
2. `TestYQExpressionConstraint`: parametrize valid expressions (`".name"`, `".name | length"`, `".name | ascii_downcase"`) into single parametrized test
3. `TestConfigFormatConstraint`: parametrize valid formats (`"json"`, `"yaml"`, `"toml"`, `"JSON"`) and invalid formats (`"xml"`, `"invalid"`) separately
4. `TestIntegerConstraint`: parametrize valid integers (`"42"`, `"0"`, `"-1"`) and invalid values (`"3.14"`, `"abc"`) separately
5. `TestJSONKeyConstraint`: parametrize valid keys (`"name"`, `"db.host"`, `"items.0"`)
6. `TestJSONValueConstraint`: parametrize valid values (`'"hello"'`, `"42"`, `"true"`, `"null"`, `"[1,2]"`, `'{"a":1}'`)
7. `TestFilePathConstraint`: parametrize valid paths and invalid paths separately

For each parametrization: Keep the individual assertion logic. Only combine tests that have identical assertion patterns (e.g., all `assert result.valid is True`). Tests with unique assertions (like checking `is_partial`, `suggestions`, or `remaining_pattern`) must remain as individual test methods.

**test_yq_wrapper.py (TEST-04):**

`TestVersionParsing` class (lines 725-758) has 8 small tests that are perfect parametrize candidates:

1. Parametrize `_parse_version` tests:

   ```python
   @pytest.mark.parametrize("version_str,expected", [
       ("v4.52.2", (4, 52, 2)),
       ("4.52.2", (4, 52, 2)),
       ("v4.53.0-rc1", (4, 53, 0)),
   ])
   def test_parse_version(self, version_str, expected):
   ```

2. Parametrize `_version_meets_minimum` tests:
   ```python
   @pytest.mark.parametrize("version,minimum,expected", [
       ("v4.52.2", "v4.52.2", True),   # exact match
       ("v4.53.0", "v4.52.2", True),   # newer patch
       ("v4.51.0", "v4.52.2", False),  # older
       ("v4.60.0", "v4.52.2", True),   # newer minor
       ("v5.0.0", "v4.52.2", True),    # newer major
   ])
   def test_version_meets_minimum(self, version, minimum, expected):
   ```

Also in `TestYQResultModel` class (lines 186-222): `test_yqresult_default_values` only checks types -- strengthen by also asserting default values:

- `assert result.stdout == ""`
- `assert result.returncode == 0`
- `assert result.stderr == ""`
- `assert result.format_type is None` (or whatever the actual defaults are)

Read the `YQResult` model definition first to verify actual default values before writing assertions.
</action>
<verify>

```bash
uv run pytest packages/mcp_json_yaml_toml/tests/test_diff.py packages/mcp_json_yaml_toml/tests/test_lmql_constraints.py packages/mcp_json_yaml_toml/tests/test_yq_wrapper.py -v --no-header 2>&1 | tail -40
```

All tests pass. Parametrized tests appear in output with bracket notation (e.g., `test_parse_version[v4.52.2-expected0]`). Total test count should be same or slightly different (parametrize may change count if tests were merged).
</verify>
<done>
Repetitive test data in test_diff.py (missing file tests), test_lmql_constraints.py (valid/invalid constraint inputs), and test_yq_wrapper.py (version parsing/comparison) converted to @pytest.mark.parametrize. YQResult default value assertions strengthened. All tests pass.
</done>
</task>

</tasks>

<verification>
```bash
# Run full test suite to ensure no regressions
uv run pytest --no-header -q 2>&1 | tail -10

# Verify parametrize usage increased

grep -c "@pytest.mark.parametrize" packages/mcp_json_yaml_toml/tests/test_diff.py packages/mcp_json_yaml_toml/tests/test_lmql_constraints.py packages/mcp_json_yaml_toml/tests/test_yq_wrapper.py

# Verify verify_features.py has assertions

grep -c "assert" packages/mcp_json_yaml_toml/tests/verify_features.py

# Verify test_schemas.py no longer imports \_parse_extension_schemas directly

grep "\_parse_extension_schemas" packages/mcp_json_yaml_toml/tests/test_schemas.py || echo "No direct \_parse_extension_schemas imports"

# Run linting on modified files

uv run prek run --files packages/mcp_json_yaml_toml/tests/verify_features.py packages/mcp_json_yaml_toml/tests/test_schemas.py packages/mcp_json_yaml_toml/tests/test_diff.py packages/mcp_json_yaml_toml/tests/test_lmql_constraints.py packages/mcp_json_yaml_toml/tests/test_yq_wrapper.py

```
</verification>

<success_criteria>
1. verify_features.py::test_hints() contains assert statements (not just print)
2. test_schemas.py tests _parse_extension_schemas through _build_ide_schema_index or IDESchemaProvider
3. test_diff.py missing-file tests use @pytest.mark.parametrize
4. test_lmql_constraints.py valid/invalid input patterns use @pytest.mark.parametrize
5. test_yq_wrapper.py version parsing tests use @pytest.mark.parametrize
6. All tests pass
7. All linting gates pass on modified files
</success_criteria>

<output>
After completion, create `.planning/phases/08-test-quality/08-01-SUMMARY.md`
</output>
```
